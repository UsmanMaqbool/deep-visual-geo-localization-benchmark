python3 train.py --dataset_name=pitts30k --lr=0.00001 --backbone=vgg16 --criterion=triplet --pretrain=offtheshelf
/home/leo/anaconda3/envs/vpr-benchmark/lib/python3.8/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: /home/leo/anaconda3/envs/vpr-benchmark/lib/python3.8/site-packages/torchvision/image.so: undefined symbol: _ZN5torch3jit17parseSchemaOrNameERKNSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEE
  warn(f"Failed to load image Python extension: {e}")
/home/leo/anaconda3/envs/vpr-benchmark/lib/python3.8/site-packages/scipy/__init__.py:143: UserWarning: A NumPy version >=1.19.5 and <1.27.0 is required for this version of SciPy (detected version 1.19.4)
  warnings.warn(f"A NumPy version >={np_minversion} and <{np_maxversion}"
2023-10-23 09:41:03   Arguments: Namespace(aggregation='netvlad', backbone='vgg16', brightness=0, cache_refresh_rate=1000, contrast=0, criterion='triplet', dataset_name='pitts30k', datasets_folder='datasets_vg/datasets', device='cuda', efficient_ram_testing=False, epochs_num=1000, fc_output_dim=None, freeze_te=None, horizontal_flip=False, hue=0, infer_batch_size=32, l2='before_pool', lr=1e-05, lr_crn_layer=0.005, lr_crn_net=0.0005, majority_weight=0.01, margin=0.1, mining='partial', neg_samples_num=1000, negs_num_per_query=10, netvlad_clusters=64, num_workers=8, off_the_shelf='imagenet', optim='adam', patience=3, pca_dataset_folder=None, pca_dim=None, pretrain='offtheshelf', queries_per_epoch=5000, rand_perspective=0, random_resized_crop=0, random_rotation=0, recall_values=[1, 5, 10, 20], resize=[480, 640], resume=None, saturation=0, save_dir='logs/default/2023-10-23_09-41-03', seed=43, test_method='hard_resize', train_batch_size=4, train_positives_dist_threshold=10, trunc_te=None, val_positive_dist_threshold=25)
2023-10-23 09:41:03   The outputs are being saved in logs/default/2023-10-23_09-41-03
2023-10-23 09:41:03   Using 1 GPUs and 32 CPUs
2023-10-23 09:41:03   Loading dataset pitts30k from folder datasets_vg/datasets
2023-10-23 09:41:03   There are 96 queries without any positives within the training set. They won't be considered as they're useless for training.
/home/leo/anaconda3/envs/vpr-benchmark/lib/python3.8/site-packages/numpy/core/_asarray.py:83: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray
  return array(a, dtype, copy=False, order=order)
2023-10-23 09:41:03   Train query set: < TripletsDataset, pitts30k - #database: 10000; #queries: 7320 >
2023-10-23 09:41:03   Val set: < BaseDataset, pitts30k - #database: 10000; #queries: 7608 >
2023-10-23 09:41:03   Test set: < BaseDataset, pitts30k - #database: 10000; #queries: 6816 >
/home/leo/anaconda3/envs/vpr-benchmark/lib/python3.8/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.
  warnings.warn(
/home/leo/anaconda3/envs/vpr-benchmark/lib/python3.8/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=VGG16_Weights.IMAGENET1K_V1`. You can also use `weights=VGG16_Weights.DEFAULT` to get the most up-to-date weights.
  warnings.warn(msg)
2023-10-23 09:41:04   Train last layers of the vgg16, freeze the previous ones
Matconvnet Loaded
2023-10-23 09:41:04   Extracting features to initialize NetVLAD layer
100%|███████████████████████████████████████████████████████████████| 16/16 [00:05<00:00,  2.93it/s]
2023-10-23 09:41:45   NetVLAD centroids shape: (64, 512)
2023-10-23 09:41:45   Output dimension of the model is 32768, with 188.09 GFLOPs
2023-10-23 09:41:45   Start training epoch: 00
2023-10-23 09:41:45   Cache: 0 / 5
100%|█████████████████████████████████████████████████████████████| 176/176 [00:50<00:00,  3.49it/s]
100%|███████████████████████████████████████████████████████████| 1000/1000 [01:13<00:00, 13.58it/s]
100%|█████████████████████████████████████████████████████████████| 250/250 [02:20<00:00,  1.79it/s]
2023-10-23 09:46:09   Epoch[00](0/5): current batch triplet loss = 0.0155, average epoch triplet loss = 0.0300
2023-10-23 09:46:09   Cache: 1 / 5
100%|█████████████████████████████████████████████████████████████| 175/175 [00:52<00:00,  3.34it/s]
100%|███████████████████████████████████████████████████████████| 1000/1000 [01:35<00:00, 10.49it/s]
100%|█████████████████████████████████████████████████████████████| 250/250 [02:46<00:00,  1.50it/s]
2023-10-23 09:51:24   Epoch[00](1/5): current batch triplet loss = 0.0200, average epoch triplet loss = 0.0281
2023-10-23 09:51:24   Cache: 2 / 5
100%|█████████████████████████████████████████████████████████████| 176/176 [00:55<00:00,  3.16it/s]
100%|███████████████████████████████████████████████████████████| 1000/1000 [01:26<00:00, 11.54it/s]
100%|█████████████████████████████████████████████████████████████| 250/250 [02:28<00:00,  1.69it/s]
2023-10-23 09:56:14   Epoch[00](2/5): current batch triplet loss = 0.0174, average epoch triplet loss = 0.0259
2023-10-23 09:56:14   Cache: 3 / 5
100%|█████████████████████████████████████████████████████████████| 176/176 [00:53<00:00,  3.29it/s]
100%|███████████████████████████████████████████████████████████| 1000/1000 [01:25<00:00, 11.70it/s]
100%|█████████████████████████████████████████████████████████████| 250/250 [02:25<00:00,  1.72it/s]
2023-10-23 10:00:59   Epoch[00](3/5): current batch triplet loss = 0.0279, average epoch triplet loss = 0.0244
2023-10-23 10:00:59   Cache: 4 / 5
100%|█████████████████████████████████████████████████████████████| 175/175 [00:51<00:00,  3.37it/s]
100%|███████████████████████████████████████████████████████████| 1000/1000 [01:22<00:00, 12.07it/s]
100%|█████████████████████████████████████████████████████████████| 250/250 [02:44<00:00,  1.52it/s]
2023-10-23 10:05:58   Epoch[00](4/5): current batch triplet loss = 0.0110, average epoch triplet loss = 0.0232
2023-10-23 10:05:58   Finished epoch 00 in 0:24:12, average epoch triplet loss = 0.0232
2023-10-23 10:05:58   Extracting database features for evaluation/testing
100%|█████████████████████████████████████████████████████████████| 313/313 [04:03<00:00,  1.28it/s]
2023-10-23 10:10:02   Extracting queries features for evaluation/testing
100%|█████████████████████████████████████████████████████████████| 238/238 [03:22<00:00,  1.17it/s]
2023-10-23 10:13:25   Calculating recalls
2023-10-23 10:13:39   Recalls on val set < BaseDataset, pitts30k - #database: 10000; #queries: 7608 >: R@1: 86.4, R@5: 95.7, R@10: 97.6, R@20: 98.7
